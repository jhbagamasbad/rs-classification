{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZQUh6f5uNKJ"
   },
   "source": [
    "All datasets of NBA players' per season averages were acquired from [basketball-reference.com](https://www.basketball-reference.com/). For the purpose of demonstrating how the datasets used for obtaining individual NBA player's composite Rank Score for the 2024-2025 season, I have included in the repository the final processed datasets as a comparison. Further instructions will be provided as clarification for the modifications in the datasets, as you go on with this Python notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQxG5_sQv04C"
   },
   "source": [
    "Datasets acquired from basketball-reference.com were exported as a CSV file in Excel. When exporting, do not add the \"Rk\" and \"Awards\" columns. Below are the links of the sources for the datasets:\n",
    "\n",
    "\n",
    "*   [2019-20 NBA Player Stats: Per Game](https://www.basketball-reference.com/leagues/NBA_2020_per_game.html)\n",
    "*   [2020-21 NBA Player Stats: Per Game](https://www.basketball-reference.com/leagues/NBA_2021_per_game.html)\n",
    "*   [2021-22 NBA Player Stats: Per Game](https://www.basketball-reference.com/leagues/NBA_2022_per_game.html)\n",
    "*   [2022-23 NBA Player Stats: Per Game](https://www.basketball-reference.com/leagues/NBA_2023_per_game.html)\n",
    "*   [2023-24 NBA Player Stats: Per Game](https://www.basketball-reference.com/leagues/NBA_2024_per_game.html)\n",
    "*   [2024-25 NBA Player Stats: Per Game](https://www.basketball-reference.com/leagues/NBA_2025_per_game.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51636,
     "status": "ok",
     "timestamp": 1759305216597,
     "user": {
      "displayName": "J-NEIL BAGAMASBAD",
      "userId": "03177234785450833391"
     },
     "user_tz": -480
    },
    "id": "24jrvfIW5a-Z",
    "outputId": "dde1386e-508f-425e-fb14-799354338e04"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().resolve().parent))  # add repo root to sys.path\n",
    "\n",
    "from project_paths import (\n",
    "    RAW_DIR, EDITED_DIR, FINAL_DIR, ANALYSIS_DIR, TEMP_DIR, DATA_DIR, ROOKIES_PATH\n",
    ")\n",
    "\n",
    "INPUT_DIR    = RAW_DIR\n",
    "GLOB_PATTERN = \"*Season.csv\"   # e.g., \"2021-2022 Season.csv\"\n",
    "OUTPUT_DIR   = TEMP_DIR\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1759305216633,
     "user": {
      "displayName": "J-NEIL BAGAMASBAD",
      "userId": "03177234785450833391"
     },
     "user_tz": -480
    },
    "id": "-j82CjUgPM5S"
   },
   "outputs": [],
   "source": [
    "# Column Names from basketball-reference.com site\n",
    "COLUMN_NAMES = [\n",
    "    'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
    "    '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'ORB',\n",
    "    'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'Player-additional'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759305216650,
     "user": {
      "displayName": "J-NEIL BAGAMASBAD",
      "userId": "03177234785450833391"
     },
     "user_tz": -480
    },
    "id": "nZ9BkyhGPl4q"
   },
   "outputs": [],
   "source": [
    "# For datasets without first row header\n",
    "def load_csv_force_schema(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a CSV that may or may not have a header row; force expected schema and coerce numerics.\"\"\"\n",
    "    # First try: no header\n",
    "    df = pd.read_csv(path, header=None, dtype=str)\n",
    "    if df.shape[1] == len(COLUMN_NAMES):\n",
    "        df.columns = COLUMN_NAMES\n",
    "    else:\n",
    "        # Second try: with header\n",
    "        try:\n",
    "            df2 = pd.read_csv(path)\n",
    "            if list(df2.columns[:len(COLUMN_NAMES)]) == COLUMN_NAMES:\n",
    "                df = df2.copy()\n",
    "            else:\n",
    "                # Fallback: trim or pad columns to expected width\n",
    "                df = df.iloc[:, :len(COLUMN_NAMES)].copy()\n",
    "                if df.shape[1] < len(COLUMN_NAMES):\n",
    "                    for _ in range(len(COLUMN_NAMES) - df.shape[1]):\n",
    "                        df[df.shape[1]] = np.nan\n",
    "                df.columns = COLUMN_NAMES\n",
    "        except Exception:\n",
    "            # Last resort: enforce width from first attempt\n",
    "            df = df.iloc[:, :len(COLUMN_NAMES)].copy()\n",
    "            if df.shape[1] < len(COLUMN_NAMES):\n",
    "                for _ in range(len(COLUMN_NAMES) - df.shape[1]):\n",
    "                    df[df.shape[1]] = np.nan\n",
    "            df.columns = COLUMN_NAMES\n",
    "\n",
    "    # Coerce numeric columns where sensible\n",
    "    numeric_cols = [\n",
    "        'Age','G','GS','MP','FG','FGA','3P','3PA','2P','2PA','FT','FTA',\n",
    "        'ORB','DRB','TRB','AST','STL','BLK','TOV','PTS'\n",
    "    ]\n",
    "    for c in numeric_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Players' Registered Suffixes\n",
    "_SUFFIXES = {\"Jr.\", \"Sr.\", \"II\", \"III\", \"IV\", \"V\"}\n",
    "\n",
    "# Changing of viewing names with Lastname first in All Caps.\n",
    "def reformat_player_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert 'First [Middles] Last [Suffix]' -> 'LAST, First [Middles] [Suffix]'.\n",
    "    Preserves middle names; supports suffixes in _SUFFIXES.\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return name\n",
    "    s = name.strip()\n",
    "    if not s:\n",
    "        return s\n",
    "    parts = s.split()\n",
    "    has_suffix = parts[-1] in _SUFFIXES\n",
    "    if has_suffix and len(parts) >= 3:\n",
    "        suffix = parts[-1]\n",
    "        last = parts[-2]\n",
    "        first = parts[0]\n",
    "        middle = \" \".join(parts[1:-2])\n",
    "        return f\"{last.upper()}, {first}\" + (f\" {middle}\" if middle else \"\") + f\" {suffix}\"\n",
    "    elif len(parts) >= 2:\n",
    "        last = parts[-1]\n",
    "        first = parts[0]\n",
    "        middle = \" \".join(parts[1:-1])\n",
    "        return f\"{last.upper()}, {first}\" + (f\" {middle}\" if middle else \"\")\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# Pipeline step for Reformating player names from source datasets\n",
    "def step_reformat_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['Player'] = df['Player'].astype(str).apply(reformat_player_name)\n",
    "    return df\n",
    "\n",
    "# Pipeline step for determining if a player changed teams midseason\n",
    "def step_duplicate_and_reorder_team_pos(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # Duplicate\n",
    "    df['NEW'] = df['Team']\n",
    "    df['Pos2'] = df['Pos']\n",
    "    # Rename originals\n",
    "    df = df.rename(columns={'Team': 'OLD', 'Pos': 'Pos1'})\n",
    "    # Reorder to place NEW after OLD and Pos2 after Pos1\n",
    "    cols = list(df.columns)\n",
    "    def move_after(cols_list, col_to_move, anchor):\n",
    "        cols_list = cols_list.copy()\n",
    "        if col_to_move in cols_list and anchor in cols_list:\n",
    "            cols_list.remove(col_to_move)\n",
    "            idx = cols_list.index(anchor)\n",
    "            cols_list.insert(idx + 1, col_to_move)\n",
    "        return cols_list\n",
    "    cols = move_after(cols, 'NEW', 'OLD')\n",
    "    cols = move_after(cols, 'Pos2', 'Pos1')\n",
    "    return df[cols]\n",
    "\n",
    "# Pipeline step for dropping categories not used in analysis\n",
    "def step_drop_unwanted(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    columns_to_delete = [\n",
    "        'FG', 'FGA', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA',\n",
    "        'ORB', 'DRB', 'Player-additional'\n",
    "    ]\n",
    "    drop_cols = [c for c in columns_to_delete if c in df.columns]\n",
    "    return df.drop(columns=drop_cols)\n",
    "\n",
    "# Pipeline step for input of change of teams for players who transferred teams mid season\n",
    "def step_apply_old_new_changes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Within each file, for consecutive duplicate Players:\n",
    "      - Set the FIRST row's 'OLD' to the second-to-last row's OLD\n",
    "      - Set the FIRST row's 'NEW' to the last row's NEW\n",
    "    All rows remain; only the first row of each duplicate block is updated.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if not {'OLD', 'NEW', 'Player'}.issubset(df.columns):\n",
    "        return df\n",
    "\n",
    "    i = 0\n",
    "    n = len(df)\n",
    "    while i < n:\n",
    "        player = df.loc[i, 'Player']\n",
    "        start = i\n",
    "        # Advance through consecutive duplicates of the same Player\n",
    "        while i + 1 < n and df.loc[i + 1, 'Player'] == player:\n",
    "            i += 1\n",
    "\n",
    "        if i > start:  # found a block of duplicates [start..i]\n",
    "            # second-to-last OLD -> first row's OLD\n",
    "            df.at[start, 'OLD'] = df.at[i - 1, 'OLD']\n",
    "            # last NEW -> first row's NEW\n",
    "            df.at[start, 'NEW'] = df.at[i, 'NEW']\n",
    "\n",
    "        i += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1759305216677,
     "user": {
      "displayName": "J-NEIL BAGAMASBAD",
      "userId": "03177234785450833391"
     },
     "user_tz": -480
    },
    "id": "4S_tpNbdSb4y"
   },
   "outputs": [],
   "source": [
    "# Define pipeline order:\n",
    "#    - Names -> duplicate/reorder team/pos -> drop cols -> per-file duplicate logic\n",
    "BASE_STEPS = [\n",
    "    step_reformat_names,\n",
    "    step_duplicate_and_reorder_team_pos,\n",
    "    step_apply_old_new_changes,\n",
    "    step_drop_unwanted\n",
    "]\n",
    "\n",
    "def run_pipeline_on_file(path: Path, steps=BASE_STEPS) -> pd.DataFrame:\n",
    "    df = load_csv_force_schema(path)\n",
    "    for step in steps:\n",
    "        df = step(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1759305217092,
     "user": {
      "displayName": "J-NEIL BAGAMASBAD",
      "userId": "03177234785450833391"
     },
     "user_tz": -480
    },
    "id": "KSm-XGEoXUYi"
   },
   "outputs": [],
   "source": [
    "# Discover files and process (save each season to Excel)\n",
    "files = sorted(INPUT_DIR.glob(GLOB_PATTERN))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No files matched {INPUT_DIR}/{GLOB_PATTERN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "executionInfo": {
     "elapsed": 11714,
     "status": "ok",
     "timestamp": 1759305228803,
     "user": {
      "displayName": "J-NEIL BAGAMASBAD",
      "userId": "03177234785450833391"
     },
     "user_tz": -480
    },
    "id": "2_h_k9McTEsD",
    "outputId": "d2ca4c2c-f1c8-43a8-e515-63c3e2e29013"
   },
   "outputs": [],
   "source": [
    "# Save files to TEMP folder\n",
    "processed = []\n",
    "\n",
    "for f in files:\n",
    "    cleaned = run_pipeline_on_file(f)  # includes per-file duplicate check\n",
    "    out_name = f\"{f.stem}.xlsx\"   # e.g., \"2019-2020 Season.xlsx\"\n",
    "    out_path = OUTPUT_DIR / out_name\n",
    "    cleaned.to_excel(out_path, index=False)  # requires openpyxl or xlsxwriter\n",
    "    processed.append(str(out_path))\n",
    "\n",
    "display({\n",
    "    \"Processed files\": [f.name for f in files],\n",
    "    \"Saved Excel files\": processed,\n",
    "})\n",
    "\n",
    "# Peek at a processed season\n",
    "try:\n",
    "    peek_latest = processed[5]\n",
    "    preview_df = pd.read_excel(peek_latest)\n",
    "    display(preview_df.head(10))\n",
    "except Exception as e:\n",
    "    print(\"Preview skipped:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aw3YQWU3zQ9Z"
   },
   "source": [
    "**This next step is important.**\n",
    "\n",
    "Before we proceed, since there are now two columns for the most played playing positions of players, we need to manually modify them.\n",
    "\n",
    "A good example is the Luka Dončić trade of 2024-2025. During his [time in Dallas for that season](https://www.basketball-reference.com/teams/DAL/2025.html#all_pbp_stats) (Look at the play-by-play section if link does not directly load there) he played 73% of the time he was on the court as a Point Guard, and 27% as Shooting Guard, while [as a Laker](https://www.basketball-reference.com/teams/LAL/2025.html#all_pbp_stats) he played 45% as a Point Guard, 43% as a Shooting Guard and 12% as a Small Forward. For simplicity in determining his two most dominant playing positions, he must have played at least 60% of the total percentage allowed for each position. So as a Maverick, given that he played two positions (PG and SG), the allowed percentage for each position is an even 50%. So 60% of 50% should be 30% in order for a position to qualify as dominant playing position for him. Since he played only 27% as a Shooting Guard, for his time in Dallas in 2024-2025 he can qualify as only playing the Point Guard position in both columns for playing positions (Pos1 and Pos2).\n",
    "\n",
    "As a Laker, we can change his entry there as Pos1 = PG, and Pos2 = SG, given that he played 43% or more for both positions. Had he played 20% as a Small Forward and the remaining two positions also had 20% or more, We would list his Pos1 as Point Guard (given that it would be his most dominant position), and his Pos2 = SF. Although he qualified as SG as well, we go in sequence of playing positions (PG -> SG -> SF -> PF -> C or PG <- SG <- SF <- PF <- C) when a player is dominant in multiple positions. This will be further clarified when computing for the per season rank score of players.\n",
    "\n",
    "If you wish to skip this part, I have included in the repository the edited datasets required for this part of the data cleaning. The folder is titled as \"EDITED\". I also edited names for 'Tristan da Silva' and 'Luc Mbah a Moute' given that their last names have more than one word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759305228807,
     "user": {
      "displayName": "J-NEIL BAGAMASBAD",
      "userId": "03177234785450833391"
     },
     "user_tz": -480
    },
    "id": "NivkbpOU6SuJ"
   },
   "outputs": [],
   "source": [
    "# Load the manually edited Excel files\n",
    "MANUAL_DIR   = EDITED_DIR\n",
    "MANUAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Final output folder\n",
    "FINAL_DIR   = FINAL_DIR\n",
    "FINAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MANUAL_GLOB = \"*Season.xlsx\"  # matches names like \"2019-2020 Season.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1759305228821,
     "user": {
      "displayName": "J-NEIL BAGAMASBAD",
      "userId": "03177234785450833391"
     },
     "user_tz": -480
    },
    "id": "TYNn1OWcWScZ"
   },
   "outputs": [],
   "source": [
    "# Function to get proper Pos1 and Pos2 values\n",
    "def calculate_positions(df):\n",
    "    # Define the order of positions for adjacency checks\n",
    "    position_order = ['PG', 'SG', 'SF', 'PF', 'C']\n",
    "\n",
    "    # Group data by player to handle each player's entries\n",
    "    grouped = df.groupby('Player')\n",
    "\n",
    "    # Iterate over each player's group\n",
    "    for player, group in grouped:\n",
    "        # Only process players with multiple entries\n",
    "        if len(group) > 1:\n",
    "            # Separate the first entry (season-long stats) and team-specific entries\n",
    "            season_long_entry = group.iloc[0]  # First entry\n",
    "            team_entries = group.iloc[1:]       # All other entries\n",
    "\n",
    "            # Initialize a dictionary to store total counts for each position\n",
    "            position_counts = defaultdict(int)\n",
    "\n",
    "            # Start from the most recent team entry to the one before the first entry\n",
    "            for _, row in team_entries[::-1].iterrows():  # Reverse order\n",
    "                pos1, pos2 = row['Pos1'], row['Pos2']\n",
    "                games_played = row['G']\n",
    "\n",
    "                # Add games played to the respective position counts\n",
    "                position_counts[pos1] += games_played\n",
    "                if pos1 != pos2:\n",
    "                    # Check if positions are adjacent or have intermediate positions\n",
    "                    pos1_index = position_order.index(pos1)\n",
    "                    pos2_index = position_order.index(pos2)\n",
    "\n",
    "                    # If adjacent, just count pos2\n",
    "                    if abs(pos1_index - pos2_index) == 1:\n",
    "                        position_counts[pos2] += games_played\n",
    "                    # If they skip 1 or 2 positions, include intermediates\n",
    "                    elif abs(pos1_index - pos2_index) <= 2:\n",
    "                        # Determine range based on order in the sequence\n",
    "                        start, end = sorted([pos1_index, pos2_index])\n",
    "                        for i in range(start + 1, end):\n",
    "                            intermediate_position = position_order[i]\n",
    "                            position_counts[intermediate_position] += games_played\n",
    "                        # Count pos2 as well\n",
    "                        position_counts[pos2] += games_played\n",
    "\n",
    "            # Determine the most and second-most frequent positions based on counts\n",
    "            sorted_positions = sorted(position_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            # Update season-long entry with the calculated Pos1 and Pos2\n",
    "            if sorted_positions:\n",
    "                # Assign most frequent position\n",
    "                season_long_entry['Pos1'] = sorted_positions[0][0]  # Most frequent position\n",
    "\n",
    "                # Assign second most frequent position or fallback to Pos1\n",
    "                if len(sorted_positions) > 1:\n",
    "                    season_long_entry['Pos2'] = sorted_positions[1][0]  # Second most frequent position\n",
    "                else:\n",
    "                    season_long_entry['Pos2'] = sorted_positions[0][0]  # Fallback to the same as Pos1 if only one position\n",
    "\n",
    "            # Update the original DataFrame\n",
    "            df.loc[season_long_entry.name] = season_long_entry\n",
    "\n",
    "    return df  # Returns updated DataFrame with calculated Pos1 and Pos2 for each player\n",
    "\n",
    "# Function to drop non-total entries of players who got traded/switched teams\n",
    "def drop_duplicates_keep_first(df):\n",
    "    # Drop duplicates based on the 'Player' column, keeping only the first entry\n",
    "    df_no_duplicates = df.drop_duplicates(subset=['Player'], keep='first')\n",
    "\n",
    "    # Reset the index after dropping duplicates for a cleaner output\n",
    "    df_no_duplicates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13232,
     "status": "ok",
     "timestamp": 1759305242067,
     "user": {
      "displayName": "J-NEIL BAGAMASBAD",
      "userId": "03177234785450833391"
     },
     "user_tz": -480
    },
    "id": "BFvwGGVpWX3P",
    "outputId": "ced73ad8-d7cc-4f62-d58b-b41143b00dd5"
   },
   "outputs": [],
   "source": [
    "manual_files = sorted(MANUAL_DIR.glob(MANUAL_GLOB))\n",
    "if not manual_files:\n",
    "    raise FileNotFoundError(f\"No files matched {MANUAL_DIR}/{MANUAL_GLOB}\")\n",
    "\n",
    "final_paths = []\n",
    "for x in manual_files:\n",
    "    df_manual = pd.read_excel(x)\n",
    "\n",
    "    # Ensure G is numeric for position weighting\n",
    "    if 'G' in df_manual.columns:\n",
    "        df_manual['G'] = pd.to_numeric(df_manual['G'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Apply your functions (as-is)\n",
    "    df_manual = calculate_positions(df_manual)\n",
    "    df_manual = drop_duplicates_keep_first(df_manual)\n",
    "\n",
    "    out_path = FINAL_DIR / x.name.replace(\".xlsx\", \"_final.xlsx\")\n",
    "    df_manual.to_excel(out_path, index=False)\n",
    "    final_paths.append(str(out_path))\n",
    "\n",
    "display({\n",
    "    \"Manually edited inputs\": [f.name for f in manual_files],\n",
    "    \"Saved final Excel files\": final_paths,\n",
    "})\n",
    "\n",
    "# Peek at a final_paths season\n",
    "try:\n",
    "    peek_latest = final_paths[5]\n",
    "    preview_df = pd.read_excel(peek_latest)\n",
    "    display(preview_df.head(10))\n",
    "except Exception as e:\n",
    "    print(\"Preview skipped:\", e)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPVR2HmNI12GZZ92P7OBYe3",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
